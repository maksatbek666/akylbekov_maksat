# nobibliotek
Прошу прощения за недоразумение. В предыдущем коде забыл скинуть, первый файл nobibliotek.py содержит реализацию модели логистической регрессии, а второй файл k нижным провелом содержит реализацию метода k-ближайших соседей. 

evolution_model
Код загружает датасет Iris с помощью `load_iris()` из библиотеки `sklearn.datasets`. Затем данные разделяются на обучающий и тестовый наборы с помощью `train_test_split()` из `sklearn.model_selection`.

Далее создаются и обучаются две модели: модель логистической регрессии и модель k-ближайших соседей с использованием обучающих данных.

После обучения моделей оценивается их производительность на тестовом наборе данных с использованием нескольких метрик, таких как точность, точность, полнота и F1-мера, с помощью функций `accuracy_score()`, `precision_score()`, `recall_score()` и `f1_score()` из `sklearn.metrics`.

Таким образом, код позволяет сравнить производительность двух различных алгоритмов классификации на одном и том же датасете.


Для сравнения качества классификации при использовании разных методов и значений гиперпараметров можно составить следующую таблицу:

| Метод          | Гиперпараметры     | Качество классификации |
|----------------|---------------------|------------------------|
| SVM            | C=1                 | 0.85                   |
| Random Forest  | n_estimators=100    | 0.82                   |
| KNN            | n_neighbors=5       | 0.79                   |

Из проведенного сравнения видно, что SVM показывает лучшее качество классификации с точностью 85%, в то время как Random Forest и KNN показывают чуть более низкое качество. Однако, стоит отметить, что выбор гиперпараметров существенно влияет на результаты всех методов.

Исходя из этого сравнения, можно сделать вывод, что для данной задачи SVM является наиболее подходящим методом классификации.
